{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the camera matrix and distortion coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "def cameraMatandCoe():\n",
    "\n",
    "    # Number of corners in the x and y \n",
    "    nx = 9\n",
    "    ny = 6\n",
    "\n",
    "    objectPoints = [] # The 3D points in the real world\n",
    "    imagePoints = [] # The 2D points in an image plane\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Preparing the object points\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "    i = 0\n",
    "    imglist = []\n",
    "    # go through each image in the list\n",
    "    for fname in images:\n",
    "\n",
    "        img = cv2.imread(fname)\n",
    "\n",
    "        # Convert image to grayscale\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        if ret == True:\n",
    "            imagePoints.append(corners)\n",
    "            objectPoints.append(objp)\n",
    "\n",
    "            img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            imglist.append(img)\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Test the undistortion on an image\n",
    "    img = cv2.imread('camera_cal\\calibration1.jpg')\n",
    "\n",
    "\n",
    "    # Calibrate the camera\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objectPoints, imagePoints, img.shape[0:2], None, None)\n",
    "\n",
    "    # Find the destination image\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "#     # Visualize undistortion\n",
    "#     f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "#     ax1.imshow(img)\n",
    "#     ax1.set_title('Original Image', fontsize=30)\n",
    "#     ax2.imshow(dst)\n",
    "#     ax2.set_title('Undistorted Image', fontsize=30)\n",
    "    return dst, mtx, dist\n",
    "dst, mtx, dist = cameraMatandCoe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Here is the original raw image from the camera and the undistorted image\n",
    "# image = cv2.imread('test_images/test5.jpg')\n",
    "# img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# dst, mtx = cameraMatandCoe()\n",
    "# unDst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "# # Visualize undistortion\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "# ax1.imshow(img)\n",
    "# ax1.set_title('Original Image', fontsize=30)\n",
    "# ax2.imshow(unDst)\n",
    "# ax2.set_title('Undistorted Image', fontsize=30)\n",
    "\n",
    "def undistortImg(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     dst, mtx, dist = cameraMatandCoe()\n",
    "    unDst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return unDst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Now we are going to apply a combination of color and gradient thresholds to find the rectify binary image\n",
    "\n",
    "\n",
    "# # Convert to HLS color space and separate the S channel\n",
    "# # Note: img is the undistorted image\n",
    "# hls = cv2.cvtColor(unDst, cv2.COLOR_RGB2HLS)\n",
    "# h_channel = hls[:,:,0]\n",
    "# l_channel = hls[:,:,1]\n",
    "# s_channel = hls[:,:,2]\n",
    "\n",
    "# thresh = (90, 255)\n",
    "# s_binar = np.zeros_like(s_channel)\n",
    "# s_binar[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "\n",
    "\n",
    "# # Use HLS color space and focus using the \n",
    "\n",
    "# def abs_sobel_thresh(img, orient, sobel_kernel=3, thresh=(0, 255)):\n",
    "#     # Calculate directional gradient\n",
    "#     # Apply threshold\n",
    "    \n",
    "#      # Apply the following steps to img\n",
    "#     # 1) Convert to grayscale\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#     # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "#     if orient == 'x':\n",
    "#         sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "#     else:\n",
    "#         sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "#     # 3) Take the absolute value of the derivative or gradient\n",
    "#     abs_sobel = np.absolute(sobel)\n",
    "#     # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "#     scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "#     # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "#             # is > thresh_min and < thresh_max\n",
    "#     sbinary = np.zeros_like(scaled_sobel)\n",
    "#     sbinary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "#     # 6) Return this mask as your binary_output image\n",
    "#     return sbinary\n",
    "\n",
    "# def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "#     # Calculate gradient magnitude\n",
    "#     # Apply threshold\n",
    "    \n",
    "#      # Apply the following steps to img\n",
    "#     # 1) Convert to grayscale\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#     # 2) Take the gradient in x and y separately\n",
    "#     sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "#     sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "#     # 3) Calculate the magnitude \n",
    "#     mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "#     # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "#     scaled_sobel = np.uint8(255*mag/np.max(mag))\n",
    "#     # 5) Create a binary mask where mag thresholds are met\n",
    "#     sxbinary = np.zeros_like(mag)\n",
    "#     # 6) Return this mask as your binary_output image\n",
    "#     sxbinary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "#     return sxbinary\n",
    "\n",
    "# def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "#     # Calculate gradient direction\n",
    "#     # Apply threshold\n",
    "    \n",
    "#     # Apply the following steps to img\n",
    "#     # 1) Convert to grayscale\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#     # 2) Take the gradient in x and y separately\n",
    "#     sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "#     sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "#     # 3) Take the absolute value of the x and y gradients\n",
    "#     abs_sobelx = np.absolute(sobelx)\n",
    "#     abs_sobely = np.absolute(sobely)\n",
    "#     # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "#     arctan = np.arctan2(abs_sobely, abs_sobelx)\n",
    "#     # 5) Create a binary mask where direction thresholds are met\n",
    "#     binaryMask = np.zeros_like(arctan)\n",
    "#     binaryMask[(arctan >= thresh[0]) & (arctan <= thresh[1])] = 1\n",
    "#     # 6) Return this mask as your binary_output image\n",
    "#     return binaryMask\n",
    "\n",
    "\n",
    "# # Choose a Sobel kernel size\n",
    "# ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "# # Apply each of the thresholding functions\n",
    "# gradx = abs_sobel_thresh(unDst, orient='x', sobel_kernel=ksize, thresh=(10, 100))\n",
    "# #plt.imshow(gradx, cmap = 'gray')\n",
    "# grady = abs_sobel_thresh(unDst, orient='y', sobel_kernel=ksize, thresh=(10, 100))\n",
    "# mag_binary = mag_thresh(unDst, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "# dir_binary = dir_threshold(unDst, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "# combined = np.zeros_like(dir_binary)\n",
    "# combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "\n",
    "# # Combine the two binary thresholds\n",
    "# combined_binary = np.zeros_like(s_binar)\n",
    "# combined_binary[(s_binar == 1) | (combined == 1)] = 1\n",
    "# plt.imshow(combined_binary, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def cvtToBinary(unDst):\n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    # Note: img is the undistorted image\n",
    "    hls = cv2.cvtColor(unDst, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # Grayscale image\n",
    "    # NOTE: we already saw that standard grayscaling lost color information for the lane lines\n",
    "    # Explore gradients in other colors spaces / color channels to see what might work better\n",
    "    gray = cv2.cvtColor(unDst, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    thresh_min = 20\n",
    "    thresh_max = 100\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_thresh_min = 170\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "\n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "\n",
    "    return combined_binary\n",
    "# binary = cvtToBinary()\n",
    "\n",
    "# Visualize undistortion\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "# ax1.imshow(unDst)\n",
    "# ax1.set_title('Original Image', fontsize=30)\n",
    "# ax2.imshow(binary, cmap='gray')\n",
    "# ax2.set_title('Binary Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply perspective transform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Combination of both hough lines and normal image\n",
    "#comboImage =  weighted_img(houghTransform, initial_image, α=0.8, β=1., λ=0.)\n",
    "def perspectiveTrans(img, binary):\n",
    "    \n",
    "    # Define the source and destination points\n",
    "    src = np.float32(\n",
    "    [[180, 720], # Bottom Left\n",
    "    [1125, 720], # Bottom Right\n",
    "    [585, 450],  # Top Left\n",
    "    [690, 450]]) # Rop Right\n",
    "    dst = np.float32(\n",
    "    [[320, 720],\n",
    "    [960, 720],\n",
    "    [320, 0],\n",
    "    [960, 0]])\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_size = (gray.shape[1], gray.shape[0])\n",
    "    # Calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Calculate the inverse perspective transform\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # Warp an image\n",
    "    warped = cv2.warpPerspective(binary, M, img_size)\n",
    "    \n",
    "    return M, Minv, warped\n",
    "\n",
    "# Draw the lines for the points of interest (source)\n",
    "# # Left line\n",
    "# cv2.line(draws, (src[0][0], src[0][1]), (src[2][0], src[2][1]), (255,0,0), thickness = 5)\n",
    "# # Right Line\n",
    "# cv2.line(draws, (src[1][0], src[1][1]), (src[3][0], src[3][1]), (255,0,0), thickness = 5)\n",
    "# # Bottom Line\n",
    "# cv2.line(draws, (src[0][0], src[0][1]), (src[1][0], src[1][1]), (255,0,0), thickness = 5)\n",
    "# # Top Line\n",
    "# cv2.line(draws, (src[2][0], src[2][1]), (src[3][0], src[3][1]), (255,0,0), thickness = 5)\n",
    "\n",
    "# # Draw the lines for the destiation \n",
    "# # Left Line\n",
    "# cv2.line(draws, (dst[0][0], dst[0][1]), (dst[2][0], dst[2][1]), (255,0,0), thickness = 5)\n",
    "# # Right Line\n",
    "# cv2.line(draws, (dst[1][0], dst[1][1]), (dst[3][0], dst[3][1]), (255,0,0), thickness = 5)\n",
    "# # Bottom Line\n",
    "# cv2.line(draws, (dst[0][0], dst[0][1]), (dst[1][0], dst[1][1]), (255,0,0), thickness = 5)\n",
    "# # Top Line\n",
    "# cv2.line(draws, (dst[2][0], dst[2][1]), (dst[3][0], dst[3][1]), (255,0,0), thickness = 5)\n",
    "\n",
    "\n",
    "# # Visualize undistortion\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "# ax1.imshow(binary, cmap = 'gray')\n",
    "# ax1.set_title('Original Image', fontsize=30)\n",
    "# ax2.imshow(warpedImg, cmap = 'gray')\n",
    "# ax2.set_title('Warped Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread('test_images/straight_lines2.jpg')\n",
    "# undImg = undistortImg(image)\n",
    "# draws = undImg\n",
    "\n",
    "# src = np.float32(\n",
    "#     [[180, 720], # Bottom Left\n",
    "#     [1125, 720], # Bottom Right\n",
    "#     [585, 450],  # Top Left\n",
    "#     [690, 450]]) # Rop Right\n",
    "# dst = np.float32(\n",
    "#     [[320, 720],\n",
    "#     [960, 720],\n",
    "#     [320, 0],\n",
    "#     [960, 0]])\n",
    "\n",
    "# #Draw the lines for the points of interest (source)\n",
    "# # Left line\n",
    "# cv2.line(draws, (src[0][0], src[0][1]), (src[2][0], src[2][1]), (255,0,0), thickness = 5)\n",
    "# # Right Line\n",
    "# cv2.line(draws, (src[1][0], src[1][1]), (src[3][0], src[3][1]), (255,0,0), thickness = 5)\n",
    "# # Bottom Line\n",
    "# cv2.line(draws, (src[0][0], src[0][1]), (src[1][0], src[1][1]), (255,0,0), thickness = 5)\n",
    "# # Top Line\n",
    "# cv2.line(draws, (src[2][0], src[2][1]), (src[3][0], src[3][1]), (255,0,0), thickness = 5)\n",
    "\n",
    "# # Draw the lines for the destiation \n",
    "# # Left Line\n",
    "# cv2.line(draws, (dst[0][0], dst[0][1]), (dst[2][0], dst[2][1]), (255,0,0), thickness = 5)\n",
    "# # Right Line\n",
    "# cv2.line(draws, (dst[1][0], dst[1][1]), (dst[3][0], dst[3][1]), (255,0,0), thickness = 5)\n",
    "# # Bottom Line\n",
    "# cv2.line(draws, (dst[0][0], dst[0][1]), (dst[1][0], dst[1][1]), (255,0,0), thickness = 5)\n",
    "# # Top Line\n",
    "# cv2.line(draws, (dst[2][0], dst[2][1]), (dst[3][0], dst[3][1]), (255,0,0), thickness = 5)\n",
    "# plt.imshow(draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the lane lines using a histogram\n",
    "\n",
    "\n",
    "def findLaneLines(warpedImg):\n",
    "    # Create a historgram of the bottom half of the warped binary image\n",
    "    indicies = np.int(warpedImg.shape[0]/2)\n",
    "    histogram = np.sum(warpedImg[indicies:,:], axis=0)\n",
    "    # Create an image to draw on\n",
    "    outputImg = np.dstack((warpedImg, warpedImg, warpedImg))*255\n",
    "    \n",
    "    \n",
    "    #Save initial points where the peaks are for the left and right half of the histogram\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftxBase = np.argmax(histogram[:midpoint])\n",
    "    rightxBase = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set how many windows to fill vertically the whole frame\n",
    "    numOfWindows = 9\n",
    "\n",
    "    # Set the window height\n",
    "    windowHeight = np.int(warpedImg.shape[0]/numOfWindows)\n",
    "\n",
    "    # Store all the none 0 pixels of each axis\n",
    "    notZero = warpedImg.nonzero()\n",
    "    notZeroy = np.array(notZero[0])\n",
    "    notZerox = np.array(notZero[1])\n",
    "\n",
    "    # Keep track of the current positions\n",
    "    leftxCurrent = leftxBase\n",
    "    rightxCurrent = rightxBase\n",
    "\n",
    "    #80\n",
    "    margin = 120\n",
    "    #25\n",
    "    minpix = 10\n",
    "\n",
    "    leftLaneInds = []\n",
    "    rightLaneInds = []\n",
    "\n",
    "    # Step through every window\n",
    "    for window in range(numOfWindows):\n",
    "        # Find window boundaries\n",
    "        winyLow = warpedImg.shape[0] - (window + 1)*windowHeight\n",
    "        winyHigh = warpedImg.shape[0] - window*windowHeight\n",
    "        winxLeftLow = leftxCurrent - margin\n",
    "        winxLeftHigh = leftxCurrent + margin\n",
    "        winxRightLow = rightxCurrent - margin\n",
    "        winxRightHigh = rightxCurrent + margin\n",
    "\n",
    "        # Draw the windows\n",
    "        cv2.rectangle(outputImg,(winxLeftLow,winyLow),(winxLeftHigh,winyHigh), (0,255,0), 2)\n",
    "        cv2.rectangle(outputImg,(winxRightLow,winyLow),(winxRightHigh,winyHigh), (0,255,0), 2)\n",
    "\n",
    "        # Find and store the hot pixels\n",
    "    #         good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "    #         good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        leftInd = ((notZeroy >= winyLow) & (notZeroy < winyHigh) & (notZerox >= winxLeftLow) & (notZerox < winxLeftHigh)).nonzero()[0]\n",
    "        rightInd = ((notZeroy >= winyLow) & (notZeroy < winyHigh) & (notZerox >= winxRightLow) & (notZerox < winxRightHigh)).nonzero()[0]\n",
    "        leftLaneInds.append(leftInd)\n",
    "        rightLaneInds.append(rightInd)\n",
    "        if len(leftInd) > minpix:\n",
    "            leftxCurrent = np.int(np.mean(notZerox[leftInd]))\n",
    "        if len(rightInd) > minpix:\n",
    "            rightxCurrent = np.int(np.mean(notZerox[rightInd]))\n",
    "\n",
    "    # Concatenate the arrays of the indicies\n",
    "    leftLaneInds = np.concatenate(leftLaneInds)\n",
    "    rightLaneInds = np.concatenate(rightLaneInds)\n",
    "\n",
    "    # Extract left and right line pixels\n",
    "    leftx = notZerox[leftLaneInds]\n",
    "    lefty = notZeroy[leftLaneInds]\n",
    "    rightx = notZerox[rightLaneInds]\n",
    "    righty = notZeroy[rightLaneInds]\n",
    "\n",
    "    # Fit a line to each\n",
    "    leftFit = np.polyfit(lefty, leftx, 2)\n",
    "    rightFit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "     # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0,warpedImg.shape[0]-1, warpedImg.shape[0])\n",
    "    leftFitx = leftFit[0]*ploty**2 + leftFit[1]*ploty + leftFit[2]\n",
    "    rightFitx = rightFit[0]*ploty**2 + rightFit[1]*ploty + rightFit[2]\n",
    "    return leftLaneInds, rightLaneInds, leftx, lefty, rightx, righty, leftFit, rightFit, outputImg, notZerox, notZeroy, ploty, leftFitx, rightFitx\n",
    "# leftLaneInds, rightLaneInds, leftx, lefty, rightx, righty, leftFit, rightFit = findLaneLines(warpedImg)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## visualize the lines\n",
    "def viewLaneLines(leftLaneInds, rightLaneInds, leftFit, rightFit, warpedImg, outputImg, notZerox, notZeroy):\n",
    "    ploty = np.linspace(0, warpedImg.shape[0]-1, warpedImg.shape[0] )\n",
    "    leftFitx = leftFit[0]*ploty**2 + leftFit[1]*ploty + leftFit[2]\n",
    "    rightFitx = rightFit[0]*ploty**2 + rightFit[1]*ploty + rightFit[2]\n",
    "\n",
    "    outputImg[notZeroy[leftLaneInds], notZerox[leftLaneInds]] = [255, 0, 0]\n",
    "    outputImg[notZeroy[rightLaneInds], notZerox[rightLaneInds]] = [0, 0, 255]\n",
    "    plt.imshow(outputImg)\n",
    "    plt.plot(leftFitx, ploty, color='yellow')\n",
    "    plt.plot(rightFitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you already found a lane line before than use this to find the next\n",
    "def findLaneLinesafterFindingThem():\n",
    "    notZero = warpedImg.nonzero()\n",
    "    notZeroy = np.array(notZero[0])\n",
    "    notZerox = np.array(notZero[1])\n",
    "\n",
    "    margin = 100\n",
    "\n",
    "    leftLaneInds = ((notZerox > (leftFit[0]*(notZeroy**2) + leftFit[1]*notZeroy + leftFit[2] - margin)) & (notZerox < (leftFit[0]*(notZeroy**2) + leftFit[1]*notZeroy + leftFit[2] + margin)))\n",
    "    rightLaneInds = ((notZerox > (rightFit[0]*(notZeroy**2) + rightFit[1]*notZeroy + rightFit[2] - margin)) & (notZerox < (rightFit[0]*(notZeroy**2) + rightFit[1]*notZeroy + rightFit[2] + margin)))\n",
    "\n",
    "    # Get left and right lane line pixel positions\n",
    "    leftx = notZerox[leftLaneInds]\n",
    "    lefty = notZeroy[leftLaneInds]\n",
    "    rightx = notZerox[rightLaneInds]\n",
    "    righty = notZeroy[rightLaneInds]\n",
    "\n",
    "    # Fit the line\n",
    "    leftFit = np.polyfit(lefty, leftx, 2)\n",
    "    rightFit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0,warpedImg.shape[0]-1, warpedImg.shape[0])\n",
    "    leftFitx = leftFit[0]*ploty**2 + leftFit[1]*ploty + leftFit[2]\n",
    "    rightFitx = rightFit[0]*ploty**2 + rightFit[1]*ploty + rightFit[2]\n",
    "\n",
    "\n",
    "    ## Now visualize the rults\n",
    "    outImg = np.dstack((warpedImg, warpedImg, warpedImg))*255\n",
    "    windowImg = np.zeros_like(outImg)\n",
    "\n",
    "    # Color in left and right line\n",
    "    outImg[notZeroy[leftLaneInds], notZerox[leftLaneInds]] = [255,0,0]\n",
    "    outImg[notZeroy[rightLaneInds], notZerox[rightLaneInds]] = [0,0,255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area and recast the x and y points into usable format for cv2.fillPoly()\n",
    "    leftLinWindow1 = np.array([np.transpose(np.vstack([leftFitx-margin, ploty]))])\n",
    "    leftLinWindow2 = np.array([np.flipud(np.transpose(np.vstack([leftFitx+margin, ploty])))])\n",
    "    leftLinePts = np.hstack((leftLinWindow1, leftLinWindow2))\n",
    "    rightLineWindow1 = np.array([np.transpose(np.vstack([rightFitx-margin, ploty]))])\n",
    "    rightLineWindow2 = np.array([np.flipud(np.transpose(np.vstack([rightFitx+margin, ploty])))])\n",
    "    rightLinePts = np.hstack((rightLineWindow1, rightLineWindow2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(windowImg, np.int_([leftLinePts]), (0,255, 0))\n",
    "    cv2.fillPoly(windowImg, np.int_([rightLinePts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(outImg, 1, windowImg, 0.3, 0)\n",
    "    plt.imshow(result)\n",
    "    plt.plot(leftFitx, ploty, color='yellow')\n",
    "    plt.plot(rightFitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will warp the image back to image space and place highlight the lane\n",
    "def highlightLane(warpedImg, leftFitx, rightFitx, ploty, invCamMat, unDst):\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warpedImg).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([leftFitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([rightFitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, invCamMat, (unDst.shape[1], unDst.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(unDst, 1, newwarp, 0.3, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "def curvatureReadings(highlightedImg, ploty, leftFitx, rightFitx):\n",
    "\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    yEval = 719\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftFitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightFitx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*yEval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*yEval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "\n",
    "    #Draw the text on the image\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    st1 = str(left_curverad)\n",
    "    st2 = str(right_curverad)\n",
    "    cv2.putText(highlightedImg, 'leftCurve: ' + st1 + ' rightCurve: ' + st2 ,(10,100), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    return highlightedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # Undistor the image\n",
    "    undImg = undistortImg(image)\n",
    "    # Threshold and create a binary image\n",
    "    binaryImg = cvtToBinary(undImg)\n",
    "    # Here we apply the prespective transform in order to find lane lines\n",
    "    M, Minv, warpedImg = perspectiveTrans(undImg, binaryImg)\n",
    "    # Now we will search and find the lane lines using a histogram approach\n",
    "    leftLaneInds, rightLaneInds, leftx, lefty, rightx, righty, leftFit, rightFit, outputImg, notZerox, notZeroy, ploty, leftFitx, rightFitx = findLaneLines(warpedImg)\n",
    "    # Now we will highlight the lane\n",
    "    highlightedLane = highlightLane(warpedImg, leftFitx, rightFitx, ploty, Minv, undImg)\n",
    "    # Finally we will find the curvature\n",
    "    result = curvatureReadings(highlightedLane, ploty, leftFitx, rightFitx)\n",
    "    # return the BGR color image\n",
    "    final = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## test process_image function\n",
    "# image = cv2.imread('test_images/test6.jpg')\n",
    "# leftLaneInds, rightLaneInds, leftFit, rightFit, warpedImg, outputImg, notZerox, notZeroy = process_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewLaneLines(leftLaneInds, rightLaneInds, leftFit, rightFit, warpedImg, outputImg, notZerox, notZeroy)\n",
    "# plt.imshow(warp, cmap='gray')\n",
    "# plt.imshow(test)\n",
    "# viewLaneLines(leftLaneInds, rightLaneInds, leftFit, rightFit, warpedImg, outputImg, notZerox, notZeroy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result_video.mp4\n",
      "[MoviePy] Writing video result_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▉                                                      | 65/1261 [00:08<02:57,  6.72it/s]"
     ]
    }
   ],
   "source": [
    "# step through each image\n",
    "video = 'result_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image)\n",
    "%time project_clip.write_videofile(video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"result_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
